{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzlfQ-HluKa-"
      },
      "source": [
        "# Bag of Words\n",
        "\n",
        "Classificação de texto é uma das tarefas mais comuns em que processamento de Língua Natural pode atuar.\n",
        "\n",
        "Algoritmos de classificação normalmente precisam de uma representação numérica servindo de entrada para poder gerar uma saída (classificação). O processamento do texto então entra para, de alguma maneira, converter um texto para uma representação numérica.\n",
        "\n",
        "Uma maneira simples e que muitas vezes já é suficiente para realizar essa **transformação** de um texto para números é contar a quantidade de vezes que uma palavra aparece em um texto. Essa técnica de transformação é chamada de Bag of Words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMYs5c96yRa4"
      },
      "source": [
        "## Exemplo\n",
        "\n",
        "Para mostrar como fica a representação numérica de textos com Bag of Words (BoW) usaremos o objeto *CountVectorizer* do sklearn (que faz esse processo de transformação).\n",
        "\n",
        "Porém, primeiro é necessário ter os textos. Aqui criamos uma possível representação usando *numpy*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rS1Ca34yWji",
        "outputId": "dda2f423-2c32-4d2c-b0cd-c8027a15a2f7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "texto = np.array([\"Você\", \n",
        "                  \"Gostava tanto de você\", \n",
        "                  \"Pede a ela\", \n",
        "                  \"Ela partiu\", \n",
        "                  \"Você e eu, eu e você\"])\n",
        "texto"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Você', 'Gostava tanto de você', 'Pede a ela', 'Ela partiu',\n",
              "       'Você e eu, eu e você'], dtype='<U21')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TObj4ZbL-RTA"
      },
      "source": [
        "Passamos esse texto para ser reconhecido e transformado pelo CountVectorizer. O *sklearn* representa a saída numérica dos textos como uma matriz esparsa, onde as colunas são palavras e as linhas são os textos. Cada entrada dessa matriz terá a quantidade de vezes que uma palavra aparece nesse texto e, para evitar alocar muitos espaços com zero, o *sklearn* compacta essa saída em uma matriz esparsa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0W92ixb9PDx",
        "outputId": "4bb484c1-7308-4c08-8e8c-273d2eeb3315"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow = CountVectorizer()\n",
        "\n",
        "X = bow.fit_transform(texto)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5x8 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 11 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7D9Zvjb_aW4"
      },
      "source": [
        "Uma matriz esparsa pode ser vista como uma matriz \"normal\" usando o método *toarray()*, exemplificado na sequência. Para identificar as colunas usadas, basta usar *get_feature_names_out* no Bag of Words treinado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MRV_aYQF_7jY",
        "outputId": "85bf302a-bd65-407f-8d0e-7ef943d64984"
      },
      "source": [
        "pd.DataFrame(X.toarray(), \n",
        "             columns = bow.get_feature_names_out(),\n",
        "             index = texto)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>de</th>\n",
              "      <th>ela</th>\n",
              "      <th>eu</th>\n",
              "      <th>gostava</th>\n",
              "      <th>partiu</th>\n",
              "      <th>pede</th>\n",
              "      <th>tanto</th>\n",
              "      <th>você</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Você</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gostava tanto de você</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pede a ela</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ela partiu</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Você e eu, eu e você</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       de  ela  eu  gostava  partiu  pede  tanto  você\n",
              "Você                    0    0   0        0       0     0      0     1\n",
              "Gostava tanto de você   1    0   0        1       0     0      1     1\n",
              "Pede a ela              0    1   0        0       0     1      0     0\n",
              "Ela partiu              0    1   0        0       1     0      0     0\n",
              "Você e eu, eu e você    0    0   2        0       0     0      0     2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNsvlPrjAXx6"
      },
      "source": [
        "Agora, ao invés de passar os textos como entrada do classificador, passamos a representação numérica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-HgAKXwApCa"
      },
      "source": [
        "# Exemplo de Classificação\n",
        "\n",
        "Aqui temos como exemplo um conjunto de dados em que uma coluna representa o texto de um SMS e outra coluna se ele foi classificado como spam ou não (classe ham). As linhas a seguir fazem a leitura do dataset e uma limpeza / organização dos dados para termos apenas o necessário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4MbFJOetBGd",
        "outputId": "17226a54-c952-49e9-aef3-01165c89e21d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nlIdzeHBtTrB",
        "outputId": "70c0d4bb-dac6-4013-a33c-54ec132924ee"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "sms = pd.read_csv('/content/drive/Shareddrives/Hype - Dados (EACH)/Conteúdos/Publicáveis/Em desenvolvimento/Bag of Words/spam.csv', encoding='latin1')\n",
        "sms = sms.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
        "sms.columns = ['classe', 'texto']\n",
        "sms.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classe</th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  classe                                              texto\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WYigNiSHp01"
      },
      "source": [
        "Como é um problema da classificação, precisamos determinar nosso *target* (y) e a entrada (X)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCYNwX8Wt70m"
      },
      "source": [
        "X = sms['texto']\n",
        "y = sms['classe']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL_AC-QyHwlw"
      },
      "source": [
        "Para este exemplo de introdução ao tema, apenas separamos aleatoriamente os dados entre treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8-xDEWt-QT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hglImjZKH7kP"
      },
      "source": [
        "Então, criamos nosso bag of words com os dados de treino, e com ele fazemos a transformação dos textos de treino e teste para uma representação numérica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEDsu1p7uAX2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X_train = bow.fit_transform(X_train)\n",
        "X_test = bow.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4B7KURbIKXm"
      },
      "source": [
        "Assim, podemos usar o X (a matriz esparsa da frequência das palavras) como entrada do algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lszKP5P2uAPH"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "y_predicted = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO8PDj80Icdb"
      },
      "source": [
        "Enfim, podemos identificar o êxito na classificação.\n",
        "\n",
        "Observação: Não aplicamos nenhuma técnica de rebalanceamento das classes neste notebook, mas uma redução aleatória dos dados da classe majoritária (Random Under Sampling) levava a uma acurácia próxima de 0.9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU3ZX3S8uIxo",
        "outputId": "79f8f9cb-28d1-40bb-e84c-e3e40fc76d42"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_predicted, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.98      0.99       974\n",
            "        spam       0.90      0.99      0.95       141\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.95      0.99      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpIgpZNgI6cl"
      },
      "source": [
        "Bag of Words é uma técnica usada em Processamento de Língua Natural que auxilia na classificação de texto, por representar numericamente valores que antes eram caracteres de uma string. \n",
        "\n",
        "Para alguns problemas essa abordagem é realmente muito boa. Em outros casos porém, por seguir uma abordagem *naive* para transformar textos em números, pode ser insuficiente para gerar bons resultados e sendo necessário utilizar outra abordagem ou voltar a analisar os dados e identificar se o problema que esteja lidando realmente é viável para envolver aprendizado de máquina e classificação como um todo."
      ]
    }
  ]
}